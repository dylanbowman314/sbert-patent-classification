{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcbowma2/cs240/env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "import sentence_transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = pd.read_csv('mini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tokenize import group\n",
    "\n",
    "\n",
    "# def group_dist(s1,s2):\n",
    "#     section1,section2 = s1[2],s2[2]\n",
    "#     subsection1,subsection2 = s1[3:5],s2[3:5]\n",
    "#     group1,group2 = s1[5],s2[5]\n",
    "#     print(section1)\n",
    "\n",
    "#     if section1 != section2:\n",
    "#         return 64\n",
    "#     if subsection1 != subsection2:\n",
    "#         return 16\n",
    "#     if group1 != group2:\n",
    "#         return 4\n",
    "#     return 0\n",
    "\n",
    "# for x in mini['group_id']:\n",
    "#     for y in mini['group_id']:\n",
    "#         print(f'{x}, {y}')\n",
    "#         print(group_dist(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_level= {}\n",
    "mid_level = {}\n",
    "group_level = {}\n",
    "\n",
    "for label in mini.iterrows():\n",
    "    tl = label[1]['group_id'][2]\n",
    "    ml = label[1]['group_id'][2:5]\n",
    "    gl = label[1]['group_id'][2:6]\n",
    "    sentence = label[1]['text'].encode().decode(\"utf-8\")\n",
    "    \n",
    "    if tl in top_level:\n",
    "        top_level[tl].append(sentence)\n",
    "    else:\n",
    "        top_level[tl] = [sentence]\n",
    "    \n",
    "    if ml in mid_level:\n",
    "        mid_level[ml].append(sentence)\n",
    "    else:\n",
    "        mid_level[ml] = [sentence]\n",
    "\n",
    "    if gl in group_level:\n",
    "        group_level[gl].append(sentence)\n",
    "    else:\n",
    "        group_level[gl] = [sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_labels(classes):\n",
    "    labels = {}\n",
    "    for i,l in enumerate(classes):\n",
    "        labels[l] = float(i)\n",
    "    return labels\n",
    "\n",
    "top_labels = gen_labels(top_level)\n",
    "mid_labels = gen_labels(mid_level)\n",
    "group_labels = gen_labels(group_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 19/19 [04:49<00:00, 15.26s/it]\n",
      "Iteration: 100%|██████████| 19/19 [04:22<00:00, 13.80s/it]\n",
      "Epoch: 100%|██████████| 2/2 [09:12<00:00, 276.13s/it]\n"
     ]
    }
   ],
   "source": [
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sentences = mini['text']\n",
    "groups = mini['group_id']\n",
    "\n",
    "train_examples = []\n",
    "\n",
    "for t in group_level: \n",
    "    for k in group_level[t]:\n",
    "        train_examples.append(InputExample(texts=k, label=group_labels[t]))\n",
    "\n",
    "#Define your train dataset, the dataloader and the train loss\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=1)\n",
    "train_loss = losses.CosineSimilarityLoss(sbert_model)\n",
    "print('h')\n",
    "#Tune the model\n",
    "sbert_model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=2)\n",
    "\n",
    "\n",
    "embeddings = sbert_model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d88c74c87f51e8694957b28af56f8f9d57fbf8ebab5eb40d5fd4f68319a3140f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
